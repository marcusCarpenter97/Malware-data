""" Create malware dataset from CAPE report files. """
import os
import shutil
import json
from datetime import datetime as dt
#from sklearn.model_selection import train_test_split
import random

DATA_DIR = "/home/cape/Malware-Data/Processed/"

def split_train_test(apis, labels):  # TODO how to install sklearn? Seems broken
    return train_test_split(apis, labels, test_size=0.33, random_state=888)

def trim_data(data, max_length=512, mode='first'):
    """
    data : a list of dictionaries containing batch data.
    max_length : the size of the biggest possible API sequence after trimming.
    mode : the trimming style. Three posibilities, first, last, random.
    mode='first' keeps the fist APIs in the sequence up to max_lenght.
    mode='last' keeps the last APIs in the sequence up to max_lenght.
    mode='random' extracts a max_lenght sized sequences of sequential APIs at a random position.

    Returns a list of lists containing the trimmed APIs.
    """
    trimmed_data = []
    random.seed(888)
    for batch in data:
        if mode == "first":
            trimmed_data.extend([api_seq[:max_length] for api_seq in batch['apis']])
        if mode == "last":
            trimmed_data.extend([api_seq[-max_length:] for api_seq in batch['apis']])
        if mode == "random":
            for api_seq in batch['apis']:
                if len(api_seq) < max_length:
                    trimmed_data.append(api_seq)
                else:
                    offset = random.randint(0, len(api_seq)-max_length)
                    trimmed_data.append(api_seq[offset:offset+max_length])
    return trimmed_data

def load_lookup_table():
    with open("lookup_table.json", 'r') as lt:
        lookup_table = json.load(lt)
    return lookup_table

def load_data(data_dir):
    """ Returns a list of batch dictionaries. """

    data = []
    data_files = os.listdir(data_dir)

    for data_file in data_files:
        file_path = os.path.join(data_dir, data_file)
        with open(file_path, "r") as fp:
            data.append(json.load(fp))
    return data

def load_VT_report(path):
    report = open_json(path)
    if report:
        labels = report.get("data", {}).get("attributes",
                            {}).get("popular_threat_classification",
                            {}).get("popular_threat_category", {})
        return [label["value"] for label in labels]

def open_json(path):
    try:
        with open(path, "r") as fp:
            return json.load(fp)

    except json.decoder.JSONDecodeError as err:
        print(f"Could not open {path} - {err}")
        return None

    except FileNotFoundError as err:
        print(f"Could not open - {err}")
        return None

def make_lookup_table(batch_labels):
    """ Create a look up table containing all unique malware classes found in the VirusTotal reports. """
    lookup_table = []

    print("Preparing lookup table...")

    for batch in batch_labels:
        for sample in batch_labels[batch]:
            for malware_label in sample:
                if malware_label not in lookup_table:
                    lookup_table.append(malware_label)

    with open("lookup_table.json", "w") as fp:
        json.dump(lookup_table, fp)

    print("Lookup table saved.")
    return lookup_table

def make_labels(batch_labels, lookup_table):
    """ Make label for a malware sample based on the contents of the corresponding VirusTotal report. """

    processed_labels = dict()

    for batch in batch_labels:
        print(f"Making labels for batch: {batch}")

        processed_labels[batch] = []

        for sample in batch_labels[batch]:
            label = [0 for _ in range(len(lookup_table))]

            for malware_label in sample:
                idx = lookup_table.index(malware_label)
                label[idx] = 1

            processed_labels[batch].append(label)

    return processed_labels

def extract_apis(report):
    timestamps = []
    apis = []
    for process in report.get("behavior", {}).get("processes", {}):
        for call in process.get("calls", {}):
            timestamps.append(call["timestamp"])
            apis.append(call["api"])

    datetime_format = "%Y-%m-%d %H:%M:%S,%f"
    times = [dt.strptime(timestamp, datetime_format) for timestamp in timestamps]

    return [api for _, api in sorted(zip(times, apis))]

def save_data(batch_name, year, apis, labels, save_dir):
    data = {}
    data["name"] = batch_name
    data["year"] = year
    data["apis"] = apis
    data["labels"] = labels

    path = os.path.join(save_dir, f"{batch_name}.json")
    print(f"Saving data to {path}")
    with open(path, "w") as fp:
        json.dump(data, fp, indent=4)

def cape_to_full(cape_ranges, base_dir):

    for batch_name in cape_ranges:
        from_cape_to_full(base_dir, batch_name, cape_ranges[batch_name]["start"], cape_ranges[batch_name]["stop"])

def from_cape_to_full(base_target, batch, start, stop):
    """ Move files from CAPE directories into the Full data directory.
        One batch at a time. """
    base_cape_report_path = "/opt/CAPEv2/storage/analyses/"
    end_cape_report_path = "reports/report.json"
    base_cape_dir = "CAPE_"
    target_name = f"{base_cape_dir}{batch}"

    target_dir = os.path.join(base_target, target_name)

    try:
        os.makedirs(target_dir, exist_ok=False)
    except FileExistsError:
        print(f"Target directory already exists: {target_dir}")
        return

    for report_idx in range(start, stop):
        report_path = os.path.join(base_cape_report_path, str(report_idx), end_cape_report_path)

        report_data = open_json(report_path)

        if not report_data:
            continue

        md5 = report_data.get("target", {}).get("file", {}).get("md5", {})
        target_name = os.path.join(target_dir, md5)

        print(f"Copying {report_path} to {target_name}")

        try:
            shutil.copy(report_path, f"{target_name}.json")
        except FileNotFoundError as err:
            print(f"Could not copy - {err}")

def save_sample(base_path, year, md5, behavior, label):

    save_dir = os.path.join(base_path, year)
    file_contents = {"md5": md5, "year": year, "behavior": behavior, "label": label}

    os.makedirs(save_dir, exist_ok=True)

    file_path = os.path.join(save_dir, f"{md5}.json")

    with open(file_path, "w") as fp:
        json.dump(file_contents, fp, indent=4)

def compile_data(base_dir, target_dir, cape_ranges):
    """ Load Full data into memory, but only relevant parts such as APIs and labels. """

    base_cape_dir = "CAPE_"
    base_vt_dir = "VT_"
    benign = "benign"
    malware = "malware"
    result_dirs = os.listdir(base_dir)
    cape_dirs = [sub_dir for sub_dir in result_dirs if base_cape_dir in sub_dir]

    for cape_dir in cape_dirs:
        batch_path = os.path.join(base_dir, cape_dir)
        batch_files = os.listdir(batch_path)

        batch_name = cape_dir[len(base_cape_dir):]

        year = str(cape_ranges[batch_name]["year"])

        print(f"\n{batch_name}\n")
        batch_size = len(batch_files)

        for idx, cape_report in enumerate(batch_files):
            print(f"{idx}/{batch_size}", end="\r")

            report_path = os.path.join(batch_path, cape_report)
            report_data = open_json(report_path)

            if not report_data:
                continue

            md5 = report_data.get("target", {}).get("file", {}).get("md5", {})

            behavior = report_data.get("behavior", {})

            vt_report_path = os.path.join(base_dir, f"{base_vt_dir}{batch_name}", cape_report)
            labels = load_VT_report(vt_report_path)

            if not labels:
                if benign in cape_dir:
                    labels = [benign]
                else:
                    labels = [malware]

            save_sample(target_dir, year, md5, behavior, labels)

if __name__ == "__main__":

    base_dir = "/home/cape/Malware-Data/Full"
    target_dir = "/home/cape/Malware-Data/MultiProcess"

    with open("cape-ranges.json", "r") as fp:
        cape_ranges = json.load(fp)

    cape_to_full(cape_ranges, base_dir)
    compile_data(base_dir, target_dir, cape_ranges)
    #TODO iterate compiled data to make numerical labels.
