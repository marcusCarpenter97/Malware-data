import os
import models
import backend
import tensorflow as tf
import analysis
from pprint import pprint
#import numpy as np
#import pandas as pd
import matplotlib.pyplot as plt
from tabulate import tabulate
from sklearn.metrics import accuracy_score, f1_score, multilabel_confusion_matrix, ConfusionMatrixDisplay

SAVE_DIR = "results"

def make_latex_table(name, table, header):
    txt = tabulate(table, header, tablefmt="latex_raw")
    path = os.path.join(SAVE_DIR, name)
    with open(path, "w") as fp:
        fp.write(txt)
    return txt

def plot_training_history(hist, model_name):
    ax_legend = []
    fig, axes = plt.subplots()
    for res in hist:
        axes.plot(range(1, len(hist[res])+1), hist[res])
        ax_legend.append(res)
    fig.suptitle(f"Training curve for: {model_name}")
    axes.legend(ax_legend)
    path = os.path.join(SAVE_DIR, f"{model_name}-train-curve.png")
    fig.savefig(path)
    plt.close()

def plot_confusion_matrix(lookup_table, labels, preds, name):

    n_rows = 3
    n_cols = 5

    cm = multilabel_confusion_matrix(labels, preds.round())

    f, axes = plt.subplots(n_rows, n_cols, constrained_layout=True)
    axes = axes.ravel()
    for idx, subm in enumerate(cm):
        disp = ConfusionMatrixDisplay(subm)
        disp.plot(ax=axes[idx])
        disp.im_.colorbar.remove()
        disp.ax_.set_title(f'{lookup_table[idx]}')
        if idx not in [10, 12, 14]:  # these numbers are plot indicies to display x label.
            disp.ax_.set_xlabel('')
        if idx%n_cols!=0:
            disp.ax_.set_ylabel('')

    f.colorbar(disp.im_, ax=axes)
    path = os.path.join(SAVE_DIR, f"{name}-conf-matrix.png")
    plt.savefig(path, bbox_inches="tight")
    plt.close()

def calc_acc_and_f1(name, labels, preds):
    acc = accuracy_score(labels, preds.round())
    fone = f1_score(labels, preds.round(), average='samples', zero_division=1)
    return [name, acc, fone]

def calc_f1_categories(name, labels, preds):
    row = list(f1_score(labels, preds.round(), average=None, zero_division=1))
    row.insert(0, name)
    return row

def main():

    data = backend.load_data(backend.DATA_DIR)
    lookup_table = backend.load_lookup_table()

    # TODO How to load model configuration from file
    batch_size = 8
    epochs = 15
    n_timesteps = 1
    n_features = 16
    embedding_dimention = 16
    optimizer = "adam"
    callbacks = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.01, patience=3)]

    # The data needs to be trimmed because the sequences are too long.
    trimmed_data = []
    data_modes = ['first', 'last', 'random']

    for mode in data_modes:
        trimmed_apis = backend.trim_data(data, mode=mode)
        trimmed_strs = [" ".join(api_seq) for api_seq in trimmed_apis]
        trimmed_data.append(trimmed_strs)

    labels = []
    for batch in data:
        for label in batch['labels']:
            labels.append(label)

    number_of_outputs = len(labels[0])

    for idx, trim in enumerate(trimmed_data):
        train_x, test_x, train_y, test_y = backend.split_train_test(trim, labels)

        #print(f"\nSize of train x: {len(train_x)}\nSize of train y: {len(train_y)}\nSize of test x: {len(test_x)}\nSize of test y {len(test_y)}\n")

        vectorize_corpus = tf.data.Dataset.from_tensor_slices(train_x)
        vectorize_layer = models.train_vectorization_layer(vectorize_corpus)
        vocab_size = vectorize_layer.vocabulary_size()

        train_ds = tf.data.Dataset.from_tensor_slices((train_x, train_y)).batch(batch_size)
        test_ds = tf.data.Dataset.from_tensor_slices((test_x, test_y)).batch(batch_size)

        model_pipeline = [models.simple_embedding_model(vectorize_layer, vocab_size, embedding_dimention, number_of_outputs),
                          models.multilayer_perceptron_model(vectorize_layer, vocab_size, embedding_dimention, number_of_outputs),
                          models.lstm_model(vectorize_layer, vocab_size, embedding_dimention, batch_size, n_timesteps, n_features, number_of_outputs),
                          models.gru_model(vectorize_layer, vocab_size, embedding_dimention, batch_size, n_timesteps, n_features, number_of_outputs),
                          models.bi_lstm_model(vectorize_layer, vocab_size, embedding_dimention, batch_size, n_timesteps, n_features, number_of_outputs),
                          models.bi_gru_model(vectorize_layer, vocab_size, embedding_dimention, batch_size, n_timesteps, n_features, number_of_outputs)]

        eval_table = []
        acc_f1_table = []
        f1_table = []

        print(f"\n{data_modes[idx]}")

        for model in model_pipeline:
            print(f"\n{model.name}\n")

            model.compile(optimizer=optimizer, loss=tf.losses.BinaryCrossentropy(), metrics=["accuracy"])

            hist = model.fit(train_ds, validation_data=test_ds, epochs=epochs, callbacks=callbacks)
            plot_training_history(hist.history, model.name)

            eval_res = model.evaluate(test_ds)
            row = [model.name]
            row.extend(eval_res)
            eval_table.append(row)

            preds = model.predict(test_ds.map(lambda x, y: x))

            row = calc_acc_and_f1(model.name, test_y, preds)
            acc_f1_table.append(row)

            row = calc_f1_categories(model.name, test_y, preds)
            f1_table.append(row)

            plot_confusion_matrix(lookup_table, test_y, preds, f"{model.name}-{data_modes[idx]}")

        header = ["Model"]
        header.extend(model.metrics_names)
        txt_table = make_latex_table(f"{data_modes[idx]}-eval-table.txt", eval_table, header)

        header = ["Models", "Accuracy", "F1-score"]
        txt_table = make_latex_table(f"{data_modes[idx]}-acc-f1-table.txt", acc_f1_table, header)

        header = ["Model"]
        header.extend(lookup_table)
        txt_table = make_latex_table(f"{data_modes[idx]}-f1-table.txt", f1_table, header)

if __name__ == "__main__":
    main()
