import backend
import analysis
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

# Make data pipeline

# Create models from configuration

# Make model pipeline

# For each data slice:

#  For each model:

#   Train model on data

#   Save results

# Create tables and plots from saved results

def main():

    # Load data
    data = backend.load_data(backend.DATA_DIR)

    #analysis.calculate_api_length_stats(data)

    # Load model configuration

    # Split data into slices based on feature selection
    trimmed_first = backend.trim_data(data, mode='first')  # TODO put this in a loop [first, last, random] and append results
    trimmed_last = backend.trim_data(data, mode='last')
    trimmed_random = backend.trim_data(data, mode='random')

    # TODO make models here in a list

    labels = []
    for batch in data:
        for label in batch['labels']:
            labels.append(label)

    train_x, test_x, train_y, test_y = split_train_test(trimmed_first, labels)  # TODO put this in a loop for trim in trimmed_data
    # TODO run models

    lens = []
    for sample in trimmed_data:
        lens.append(len(sample))
    print("total samples", len(lens))
    print("avg len", np.mean(lens))
    print("min api seq", min(lens))
    print("max api seq", max(lens))

    return

if __name__ == "__main__":
    main()
